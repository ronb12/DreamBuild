# ğŸš€ DreamBuild LLM Fine-Tuning - Google Colab Guide
**Product of Bradley Virtual Solutions, LLC**

## ğŸ¯ You Can Start Training RIGHT NOW!

**What you'll create:** DreamBuild LLM v1.0 (specialized for your app!)  
**Cost:** $0 (100% FREE using Google Colab)  
**Time:** 2-6 hours (runs automatically)

---

## ğŸ“‹ **STEP-BY-STEP INSTRUCTIONS**

### **Step 1: Open Google Colab** (2 minutes)

1. Go to: **https://colab.research.google.com**
2. Sign in with your Google account
3. Click: **File â†’ New Notebook**
4. Click: **Runtime â†’ Change runtime type**
5. Select: **T4 GPU** (FREE!)
6. Click: **Save**

âœ… You now have a FREE GPU to train on!

---

### **Step 2: Install Dependencies** (3 minutes)

**Copy-paste this into first cell:**

```python
# ğŸ“¥ Install required libraries
!pip install -q transformers datasets accelerate bitsandbytes peft trl

print('âœ… Dependencies installed!')
print('ğŸ’¡ Using FREE GPU:', end=' ')
!nvidia-smi --query-gpu=name --format=csv,noheader
```

**Click:** â–¶ï¸ Run button

âœ… Libraries installed!

---

### **Step 3: Upload Training Data** (1 minute)

**Copy-paste into new cell:**

```python
# ğŸ“¤ Upload training data
from google.colab import files

print('ğŸ“ Click "Choose Files" and select dreambuild-training.jsonl')
uploaded = files.upload()

print('âœ… Training data uploaded!')
```

**Click:** â–¶ï¸ Run  
**Then:** Upload the `dreambuild-training.jsonl` file from your computer

âœ… Data uploaded!

---

### **Step 4: Load Base Model** (5-10 minutes)

**Copy-paste into new cell:**

```python
# ğŸ¤– Load TinyLlama
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
import torch

model_name = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"

# 4-bit quantization (fits in FREE GPU!)
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16
)

# Load model
print('ğŸ“¥ Downloading TinyLlama...')
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=bnb_config,
    device_map="auto"
)

tokenizer = AutoTokenizer.from_pretrained(model_name)
tokenizer.pad_token = tokenizer.eos_token

print('âœ… TinyLlama loaded on GPU!')
```

**Click:** â–¶ï¸ Run  
**Wait:** 5-10 minutes for model download

âœ… Base model ready!

---

### **Step 5: Configure LoRA** (1 minute)

**Copy-paste into new cell:**

```python
# ğŸ”§ Configure efficient fine-tuning (LoRA)
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training

model = prepare_model_for_kbit_training(model)

lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)

model = get_peft_model(model, lora_config)

print('âœ… LoRA configured!')
print('ğŸ’¡ Only training 1% of parameters (efficient!)')
```

**Click:** â–¶ï¸ Run

âœ… Model ready for training!

---

### **Step 6: Prepare Dataset** (2 minutes)

**Copy-paste into new cell:**

```python
# ğŸ“¦ Load and format training data
from datasets import load_dataset

dataset = load_dataset('json', data_files='dreambuild-training.jsonl')

def format_prompt(example):
    return {
        "text": f"""### Instruction:
You are DreamBuild AI. Detect the app type from the user's prompt.

### Prompt:
{example['prompt']}

### App Type:
{example['completion']}
"""
    }

formatted_data = dataset.map(format_prompt)

print(f'âœ… Formatted {len(formatted_data["train"])} examples!')
```

**Click:** â–¶ï¸ Run

âœ… Data formatted!

---

### **Step 7: TRAIN! ğŸ‹ï¸** (1-4 hours - automatic!)

**Copy-paste into new cell:**

```python
# ğŸš€ START TRAINING!
from transformers import TrainingArguments, Trainer

print('ğŸ“ Starting fine-tuning...')
print('â° Estimated time: 1-4 hours')
print('â˜• This runs automatically - grab coffee!\n')

training_args = TrainingArguments(
    output_dir="./dreambuild-llm-v1",
    num_train_epochs=3,
    per_device_train_batch_size=2,
    gradient_accumulation_steps=4,
    learning_rate=2e-4,
    fp16=True,
    save_steps=25,
    logging_steps=5,
    warmup_steps=10,
    report_to="none"
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=formatted_data['train'],
    tokenizer=tokenizer
)

# START!
trainer.train()

print('\nğŸ‰ TRAINING COMPLETE!')
print('âœ… You now have DreamBuild LLM v1.0!')
```

**Click:** â–¶ï¸ Run  
**Wait:** 1-4 hours (watch progress bars!)

âœ… Training done!

---

### **Step 8: Save & Download** (5-10 minutes)

**Copy-paste into new cell:**

```python
# ğŸ’¾ Save and download model
print('ğŸ’¾ Saving model...')

model.save_pretrained("./dreambuild-llm-v1-final")
tokenizer.save_pretrained("./dreambuild-llm-v1-final")

print('âœ… Model saved!')

# Zip for download
print('\nğŸ“¦ Creating zip file...')
!zip -r dreambuild-llm-v1.zip ./dreambuild-llm-v1-final

print('ğŸ“¥ Downloading to your computer...')
from google.colab import files
files.download('dreambuild-llm-v1.zip')

print('\nğŸ‰ DOWNLOAD COMPLETE!')
print('âœ… You now have DreamBuild LLM v1.0 on your computer!')
```

**Click:** â–¶ï¸ Run  
**Wait:** File downloads to your computer

âœ… Model downloaded!

---

## ğŸ¯ **AFTER TRAINING (Upload to GitHub)**

### **On Your Computer:**

```bash
# 1. Unzip the model
cd ~/Downloads
unzip dreambuild-llm-v1.zip

# 2. Go to DreamBuild folder
cd /Users/ronellbradley/Desktop/DreamBuild

# 3. Create models directory
mkdir -p models/dreambuild-llm-v1

# 4. Copy model files
cp -r ~/Downloads/dreambuild-llm-v1-final/* models/dreambuild-llm-v1/

# 5. Create GitHub release
gh release create llm-v1.0 models/dreambuild-llm-v1/* \
  --repo ronb12/DreamBuild \
  --title "DreamBuild LLM v1.0" \
  --notes "Custom AI model specialized for DreamBuild web app generation"

# 6. Get the release URL
echo "âœ… Model uploaded to GitHub!"
echo "ğŸ”— URL: https://github.com/ronb12/DreamBuild/releases/tag/llm-v1.0"
```

---

## ğŸ”§ **UPDATE DREAMBUILD TO USE YOUR MODEL**

### **Edit: `src/services/dreamBuildLLMService.js`**

Change line 13 from:
```javascript
this.modelName = "TinyLlama-1.1B-Chat-v1.0-q4f16_1"; // Generic
```

To:
```javascript
// Use YOUR custom model from GitHub!
this.modelName = "https://github.com/ronb12/DreamBuild/releases/download/llm-v1.0/model.bin";
this.isCustomModel = true;
```

Then rebuild and deploy:
```bash
npm run build
firebase deploy --only hosting
```

âœ… Now DreamBuild uses YOUR custom-trained AI!

---

## â° **TIMELINE**

**Today (Setup):** 15 minutes
- Open Colab
- Run cells 1-6

**Today/Tonight (Training):** 1-4 hours (automatic)
- Let it train while you sleep/work
- Colab runs in background

**Tomorrow (Deploy):** 30 minutes
- Download model
- Upload to GitHub
- Update DreamBuild

**Total:** Can be done in 1-2 days!

---

## ğŸ’¡ **TIPS**

### **If Session Times Out (12-hour limit):**
```python
# Save checkpoint
model.save_pretrained("./checkpoint")

# In new session, load checkpoint:
model = AutoModelForCausalLM.from_pretrained("./checkpoint")
# Continue training...
```

### **To Monitor Progress:**
- Watch the loss decrease (means it's learning!)
- Lower loss = better model
- Typical: Starts at ~2.0, ends at ~0.5-1.0

### **If Out of Memory:**
- Reduce `per_device_train_batch_size` from 2 to 1
- Increase `gradient_accumulation_steps` to 8

---

## ğŸ‰ **RESULT**

**After following this guide, you'll have:**

âœ… **DreamBuild LLM v1.0** - Your custom AI  
âœ… **Specialized** for DreamBuild patterns  
âœ… **Better** than generic TinyLlama  
âœ… **FREE** - Used only free tier  
âœ… **Hosted** on YOUR GitHub  
âœ… **Integrated** into DreamBuild  

**You can legitimately say:**
- âœ… "Powered by DreamBuild's proprietary LLM"
- âœ… "AI trained specifically for web app generation"
- âœ… "Custom model by Bradley Virtual Solutions"

---

## ğŸš€ **READY TO START?**

1. **Open:** https://colab.research.google.com
2. **Create:** New notebook
3. **Enable:** T4 GPU (Runtime â†’ Change runtime type)
4. **Copy:** Code from this guide
5. **Run:** Each cell in order
6. **Wait:** 1-4 hours
7. **Download:** Your custom model!

**You can start RIGHT NOW!** â˜•

---

*Complete step-by-step guide for fine-tuning DreamBuild LLM using 100% free resources*  
*Product of Bradley Virtual Solutions, LLC*

